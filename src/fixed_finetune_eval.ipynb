{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = 2\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU)\n",
    "\n",
    "import os\n",
    "from models import TransformerModel\n",
    "from tasks import get_task_sampler\n",
    "from samplers import get_data_sampler\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_batch(model, data_sampler, task_sampler, percent_clamped_correct=0, window_len=41, b_size=1, last_pt_clamped=True, smoothing=0):\n",
    "    task = task_sampler()\n",
    "    if torch.cuda.is_available() and model.name.split(\"_\")[0] in [\"gpt2\", \"lstm\"]:\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "\n",
    "    # sample 100 x points\n",
    "    # keep sampling a batch of 100 x points until we have % 0.5 ys>=percent_clamped\n",
    "    # then, depending on the context length, select percent_clamped *context_window (x,y) pairs, and randomly select the rest from the remaining points\n",
    "\n",
    "    num_clamped_needed = int(percent_clamped_correct*window_len)\n",
    "    num_other_needed = int(window_len - num_clamped_needed)\n",
    "\n",
    "    print(\"needed, other\", (num_clamped_needed, num_other_needed))\n",
    "\n",
    "    done = False\n",
    "    while not done: \n",
    "        xs = data_sampler.sample_xs(n_points=100, b_size=b_size)\n",
    "        time.sleep(10)\n",
    "        ys = task.evaluate(xs, noise=False, separate_noise=False)\n",
    "        \n",
    "        print(f'clamped {torch.where(ys[0]==0.5)[0].size(0)}, other {torch.where(ys[0]!=0.5)[0].size(0)}')\n",
    "        done = torch.where(ys[0]==0.5)[0].size(0) >= num_clamped_needed and torch.where(ys[0]!=0.5)[0].size(0) >= num_other_needed # use 1 bc dont want batch dim\n",
    "\n",
    "\n",
    "    # select percent_clamped_correct * window_len points\n",
    "    clamped_indices = torch.where(ys[0]==0.5)[0]\n",
    "    indices = torch.multinomial(torch.ones(len(clamped_indices)), num_clamped_needed, replacement=False)  # select indices\n",
    "    clamped_indices = clamped_indices[indices]\n",
    "\n",
    "    clamped_xs = xs[:, clamped_indices]\n",
    "    clamped_ys = ys[:, clamped_indices]\n",
    "\n",
    "    # select the rest randomly\n",
    "    remaining_indices = torch.where(ys[0]!=0.5)[0]\n",
    "    indices = torch.multinomial(torch.ones(len(remaining_indices)), num_other_needed, replacement=False)  # select indices\n",
    "    remaining_indices = remaining_indices[indices]\n",
    "\n",
    "    remaining_xs = xs[:, remaining_indices]\n",
    "    remaining_ys = ys[:, remaining_indices]\n",
    "\n",
    "    # save last point\n",
    "    if last_pt_clamped:\n",
    "        last_x, last_y = clamped_xs[:, -1], clamped_ys[:, -1]\n",
    "        clamped_xs = clamped_xs[:, :-1]\n",
    "    else:\n",
    "        last_x, last_y = remaining_xs[:, -1], remaining_ys[:, -1]\n",
    "        remaining_xs = remaining_xs[:, :-1]\n",
    "\n",
    "    # combine clamped & remaining\n",
    "    xs = torch.cat([clamped_xs, remaining_xs], dim=1)\n",
    "    ys = torch.cat([clamped_ys, remaining_ys], dim=1)\n",
    "\n",
    "    # shuffle order of xs and ys(but together)\n",
    "    perm = torch.randperm(xs.shape[1])\n",
    "    xs = xs[:, perm]\n",
    "    ys = ys[:, perm]\n",
    "\n",
    "    print(ys.shape)\n",
    "    print(last_y[:, None].shape)\n",
    "\n",
    "    # add back last point\n",
    "    xs = torch.cat((xs, last_x[:, :, None]), dim=1)\n",
    "    ys = torch.cat((ys, last_y[:, None]), dim=1)\n",
    "\n",
    "    pred = model(xs.to(device), ys.to(device)).detach()\n",
    "\n",
    "    perturbations = np.arange(-1 * smoothing, smoothing + 0.002, 0.002)\n",
    "    predictions = torch.zeros(len(perturbations), xs.shape[0], xs.shape[1])\n",
    "    predictions = pred.cpu() # (64, 41)\n",
    "\n",
    "    predictions = predictions[:, window_len-1]\n",
    "\n",
    "\n",
    "    return ys[:,  window_len-1], predictions\n",
    "\n",
    "def build_model():\n",
    "    model = TransformerModel(\n",
    "        n_dims=1,\n",
    "        n_positions=41,\n",
    "        n_embd=512,\n",
    "        n_layer=24,\n",
    "        n_head=16,\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = build_model()\n",
    "torch.cuda.set_device(0)\n",
    "model.cuda()\n",
    "\n",
    "# ckpt_path = '/home/riadoshi/alignment/Alignment/models/finetune/go_time/'\n",
    "ckpt_path = '/home/riadoshi/alignment/prev/ckpts/ckpt/'\n",
    "base_model = os.path.join(ckpt_path, \"state.pt\")\n",
    "state = torch.load(base_model, map_location='cuda:0')\n",
    "model.load_state_dict(state[\"model_state_dict\"])\n",
    "b_size = 1\n",
    "\n",
    "task_sampler = get_task_sampler(\n",
    "        \"clamped_chebyshev\", 1, b_size\n",
    ")\n",
    "\n",
    "data_sampler = get_data_sampler('gaussian', 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "needed, other (4, 37)\n",
      "clamped 6, other 94\n",
      "torch.Size([1, 40])\n",
      "torch.Size([1, 1])\n",
      "needed, other (4, 37)\n",
      "clamped 0, other 100\n",
      "clamped 0, other 100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m pc_mse \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_per_pc):\n\u001b[0;32m---> 13\u001b[0m     y, pred \u001b[38;5;241m=\u001b[39m \u001b[43meval_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_sampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_sampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpercent_clamped_correct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_pt_clamped\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_pt_clamped\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     pc_mse\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt((pred\u001b[38;5;241m-\u001b[39my)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     16\u001b[0m mse\u001b[38;5;241m.\u001b[39mappend(pc_mse\u001b[38;5;241m/\u001b[39mnum_per_pc)\n",
      "Cell \u001b[0;32mIn[128], line 20\u001b[0m, in \u001b[0;36meval_batch\u001b[0;34m(model, data_sampler, task_sampler, percent_clamped_correct, window_len, b_size, last_pt_clamped, smoothing)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done: \n\u001b[1;32m     19\u001b[0m     xs \u001b[38;5;241m=\u001b[39m data_sampler\u001b[38;5;241m.\u001b[39msample_xs(n_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, b_size\u001b[38;5;241m=\u001b[39mb_size)\n\u001b[0;32m---> 20\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     ys \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mevaluate(xs, noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, separate_noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclamped \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mwhere(ys[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0.5\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, other \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mwhere(ys[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trial one: fixed context window = 41, varying percentage clamped. \n",
    "# last point clamped\n",
    "\n",
    "# last point not clamped\n",
    "last_pt_clamped=True\n",
    "percent_clamped = [0.1]\n",
    "num_per_pc = 10\n",
    "mse = []\n",
    "\n",
    "for pc in percent_clamped:\n",
    "    pc_mse = 0\n",
    "    for _ in range(num_per_pc):\n",
    "        y, pred = eval_batch(model, data_sampler, task_sampler, percent_clamped_correct=pc, last_pt_clamped=last_pt_clamped)\n",
    "        pc_mse+= np.sqrt((pred-y)**2)\n",
    "        \n",
    "    mse.append(pc_mse/num_per_pc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "in-context-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
